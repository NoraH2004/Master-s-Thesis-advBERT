%% TEMPLATES
%% http://web.mit.edu/rsi/www/pdfs/bibtex-format.pdf
%% http://tug.ctan.org/info/biblatex-cheatsheet/biblatex-cheatsheet.pdf

misc{, 
	title = {},
	author = {},
	howpublished = {},
	year = ,
	month = ,
	note = {Accessed: 2019-02-13}
}

% Theoretical Background

% NLP

@article{prabowo2009sentiment,
  title={Sentiment analysis: A combined approach},
  author={Prabowo, Rudy and Thelwall, Mike},
  journal={Journal of Informetrics},
  volume={3},
  number={2},
  pages={143--157},
  year={2009},
  publisher={Elsevier}
}

        % history of NLP
@book{kumar2011natural,
  title={Natural language processing},
  author={Kumar, Ela},
  year={2011},
  publisher={IK International Pvt Ltd}
}

@inproceedings{Hutchins2006TheFP,
  title={The first public demonstration of machine translation : the Georgetown-IBM system , 7 th January 1954},
  author={John Hutchins},
  year={2006}
}

% competent mt
@article{carbonell1981steps,
  title={Steps toward knowledge-based machine translation},
  author={Carbonell, Jaime G and Cullingford, Richard E and Gershman, Anatole V},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  number={4},
  pages={376--392},
  year={1981},
  publisher={IEEE}
}

%word embeddings 1970
@article{catania1972chomsky,
  title={Chomsky's formal analysis of natural languages: A behavioral translation},
  author={Catania, A Charles},
  journal={Behaviorism},
  volume={1},
  number={1},
  pages={1--15},
  year={1972},
  publisher={JSTOR}
}

% disadvantages of one hot encoding
@article{rodriguez2018beyond,
  title={Beyond one-hot encoding: Lower dimensional target embedding},
  author={Rodr{\'\i}guez, Pau and Bautista, Miguel A and Gonzalez, Jordi and Escalera, Sergio},
  journal={Image and Vision Computing},
  volume={75},
  pages={21--31},
  year={2018},
  publisher={Elsevier}
}



@article{dostert1955georgetown,
  title={The georgetown-ibm experiment},
  author={Dostert, Leon E},
  journal={1955). Machine translation of languages. John Wiley \& Sons, New York},
  pages={124--135},
  year={1955}
}

%Book Corpus
@inproceedings{zhu2015aligning,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={19--27},
  year={2015}
}

%GloVe
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

%RNN Einsatzfelder u.ä.
@article{jozefowicz2016exploring,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint arXiv:1602.02410},
  year={2016}
}


%Word2Vec represenations
@manual{Bogdan:2018,
    title  = "Visualizing Word2Vec Vectors with t-SNE",
    author = "Bogdan",
    note   = "\url{https://nlpforhackers.io/word-embeddings/}",
    year   = "2018 (accessed July 31, 2020)"
}

%oxford dict
@article{dictionary1989oxford,
  title={Oxford english dictionary},
  author={Dictionary, Oxford English},
  journal={Simpson, JA \& Weiner, ESC},
  year={1989}
}


@manual{Bujokas:2020,
    title  = "Creating Word Embeddings: Coding the Word2Vec Algorithm in Python using Deep Learning",
    author = "Eligijus Bujokas",
    note   = "\url{https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8}",
    year   = "2020 (accessed July 31, 2020)"
}
https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8


%Vanishing gradient Problem
@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}

% NLP Structure Book
@book{ganegedara2018natural,
  title={Natural Language Processing with TensorFlow: Teach language to machines using Python's deep learning library},
  author={Ganegedara, Thushan},
  year={2018},
  publisher={Packt Publishing Ltd}
}




%RoBERTa
@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

%DistilBERT
@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

%XLnet
@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={5753--5763},
  year={2019}
}

%ERNIE
@article{zhang2019ernie,
  title={ERNIE: Enhanced language representation with informative entities},
  author={Zhang, Zhengyan and Han, Xu and Liu, Zhiyuan and Jiang, Xin and Sun, Maosong and Liu, Qun},
  journal={arXiv preprint arXiv:1905.07129},
  year={2019}
}




%summarization
@book{mani2001automatic,
  title={Automatic summarization},
  author={Mani, Inderjeet},
  volume={3},
  year={2001},
  publisher={John Benjamins Publishing}
}
%language identification
@article{tang2017phonetic,
  title={Phonetic temporal neural model for language identification},
  author={Tang, Zhiyuan and Wang, Dong and Chen, Yixiang and Li, Lantian and Abel, Andrew},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={26},
  number={1},
  pages={134--144},
  year={2017},
  publisher={IEEE}
}
% POS tagging
@article{schmid1994part,
  title={Part-of-speech tagging with neural networks},
  author={Schmid, Helmut},
  journal={arXiv preprint cmp-lg/9410018},
  year={1994}
}
@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

% text entailment
@inproceedings{dagan2005pascal,
  title={The PASCAL recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  pages={177--190},
  year={2005},
  organization={Springer}
}

% illustration guy jay alammar
@article{alammar2018illustrated,
  title={The Illustrated BERT, ELMo, and co},
  author={Alammar, Jay},
  journal={How NLP Cracked Transfer Learning). URL: http://jalammar. github. io/illustrated-bert},
  year={2018}
}

%count based
@article{neubig2016generalizing,
  title={Generalizing and hybridizing count-based and neural language models},
  author={Neubig, Graham and Dyer, Chris},
  journal={arXiv preprint arXiv:1606.00499},
  year={2016}
}


% textattack framework categories
% checking grammer
@inproceedings{oco2011grammar,
  title={A grammar checker for Tagalog using LanguageTool},
  author={Oco, Nathaniel and Borra, Allan},
  booktitle={Proceedings of the 9th Workshop on Asian Language Resources},
  pages={2--9},
  year={2011}
}

%semantics
@article{cer2018universal,
  title={Universal sentence encoder},
  author={Cer, Daniel and Yang, Yinfei and Kong, Sheng-yi and Hua, Nan and Limtiaco, Nicole and John, Rhomni St and Constant, Noah and Guajardo-Cespedes, Mario and Yuan, Steve and Tar, Chris and others},
  journal={arXiv preprint arXiv:1803.11175},
  year={2018}
}

% paper on adv ex in text
@article{alzantot2018generating,
  title={Generating natural language adversarial examples},
  author={Alzantot, Moustafa and Sharma, Yash and Elgohary, Ahmed and Ho, Bo-Jhang and Srivastava, Mani and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1804.07998},
  year={2018}
}

@article{garg2020bae,
  title={BAE: BERT-based Adversarial Examples for Text Classification},
  author={Garg, Siddhant and Ramakrishnan, Goutham},
  journal={arXiv preprint arXiv:2004.01970},
  year={2020}
}

%beam search
@article{tillmann2003word,
  title={Word reordering and a dynamic programming beam search algorithm for statistical machine translation},
  author={Tillmann, Christoph and Ney, Hermann},
  journal={Computational linguistics},
  volume={29},
  number={1},
  pages={97--133},
  year={2003},
  publisher={MIT Press}
}






@article{weizenbaum1966eliza,
  title={ELIZA—a computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966},
  publisher={ACM New York, NY, USA}
}
@article{bahl1989tree,
  title={A tree-based statistical language model for natural language speech recognition},
  author={Bahl, Lalit R and Brown, Peter F and de Souza, Peter V and Mercer, Robert L},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={37},
  number={7},
  pages={1001--1008},
  year={1989},
  publisher={IEEE}
}


% Language Modelling
@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@article{graves2005framewise,
  title={Framewise phoneme classification with bidirectional LSTM and other neural network architectures},
  author={Graves, Alex and Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={18},
  number={5-6},
  pages={602--610},
  year={2005},
  publisher={Elsevier}
}



% DEEP LEARNING (DNNs)
@book{buduma2017fundamentals,
  title={Fundamentals of deep learning: Designing next-generation machine intelligence algorithms},
  author={Buduma, Nikhil and Locascio, Nicholas},
  year={2017},
  publisher={" O'Reilly Media, Inc."}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{rawat2017deep,
  title={Deep convolutional neural networks for image classification: A comprehensive review},
  author={Rawat, Waseem and Wang, Zenghui},
  journal={Neural computation},
  volume={29},
  number={9},
  pages={2352--2449},
  year={2017},
  publisher={MIT Press}
}




%DNN (RNN)
@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model},
  author={Mikolov, Tom{\'a}{\v{s}} and Karafi{\'a}t, Martin and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Eleventh annual conference of the international speech communication association},
  year={2010}
}

%BERT
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}





%adversarial Examples in Text
@inproceedings{huang2011adversarial,
  title={Adversarial machine learning},
  author={Huang, Ling and Joseph, Anthony D and Nelson, Blaine and Rubinstein, Benjamin IP and Tygar, J Doug},
  booktitle={Proceedings of the 4th ACM workshop on Security and artificial intelligence},
  pages={43--58},
  year={2011}
}


% Text Attack Morris
@article{morris2020textattack,
  title={TextAttack: A framework for adversarial attacks in natural language processing},
  author={Morris, John X and Lifland, Eli and Yoo, Jin Yong and Qi, Yanjun},
  journal={arXiv preprint arXiv:2005.05909},
  year={2020}
}

%Pre-trained word representations
@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018}
}
@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}
@article{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  journal={arXiv preprint arXiv:1801.06146},
  year={2018}
}





@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{vijayaraghavan2019generating,
  title={Generating Black-Box Adversarial Examples for Text Classifiers Using a Deep Reinforced Model},
  author={Vijayaraghavan, Prashanth and Roy, Deb},
  journal={arXiv preprint arXiv:1909.07873},
  year={2019}
}

% gray box setting
@inproceedings{vivek2018gray,
  title={Gray-box adversarial training},
  author={Vivek, BS and Reddy Mopuri, Konda and Venkatesh Babu, R},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={203--218},
  year={2018}
}

% BERTology Paper
@inproceedings{Rogers2020API,
  title={A Primer in BERTology: What we know about how BERT works},
  author={Anna Rogers and Olga Kovaleva and Anna Rumshisky},
  year={2020}
}

% First adv examples in text
@inproceedings{Jia2017AdversarialEF,
  title={Adversarial Examples for Evaluating Reading Comprehension Systems},
  author={Robin Jia and Percy Liang},
  booktitle={EMNLP},
  year={2017}
}


%survey about adversairal examples in TEXT DNNs (qualitavely semi good but a good gathering of information!)
@article{zhang2019adversarial,
  title={Adversarial attacks on deep learning models in natural language processing: A survey},
  author={Zhang, Wei Emma and Sheng, Quan Z and Alhazmi, AHOUD and LI, CHENLIANG},
  journal={arXiv preprint arXiv:1901.06796},
  year={2019}
}

% BERT Paper
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}


@article{liang2017deep,
  title={Deep text classification can be fooled},
  author={Liang, Bin and Li, Hongcheng and Su, Miaoqiang and Bian, Pan and Li, Xirong and Shi, Wenchang},
  journal={arXiv preprint arXiv:1704.08006},
  year={2017}
}


@inproceedings{gao2018black,
  title={Black-box generation of adversarial text sequences to evade deep learning classifiers},
  author={Gao, Ji and Lanchantin, Jack and Soffa, Mary Lou and Qi, Yanjun},
  booktitle={2018 IEEE Security and Privacy Workshops (SPW)},
  pages={50--56},
  year={2018},
  organization={IEEE}
}

@article{jin2019bert,
  title={Is bert really robust? natural language attack on text classification and entailment},
  author={Jin, Di and Jin, Zhijing and Zhou, Joey Tianyi and Szolovits, Peter},
  journal={arXiv preprint arXiv:1907.11932},
  year={2019}
}

@article{goodman2020fastwordbug,
  title={FastWordBug: A Fast Method To Generate Adversarial Text Against NLP Applications},
  author={Goodman, Dou and Zhonghou, Lv and others},
  journal={arXiv preprint arXiv:2002.00760},
  year={2020}
}

@inproceedings{carlini2018audio,
  title={Audio adversarial examples: Targeted attacks on speech-to-text},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2018 IEEE Security and Privacy Workshops (SPW)},
  pages={1--7},
  year={2018},
  organization={IEEE}
}


%paper rietzler
@article{rietzler2019adapt,
  title={Adapt or get left behind: Domain adaptation through bert language model finetuning for aspect-target sentiment classification},
  author={Rietzler, Alexander and Stabinger, Sebastian and Opitz, Paul and Engl, Stefan},
  journal={arXiv preprint arXiv:1908.11860},
  year={2019}
}

% fine-tuning
@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2009},
  publisher={IEEE}
}


%elephant
@article{xu2020elephant,
  title={Elephant in the Room: An Evaluation Framework for Assessing Adversarial Examples in NLP},
  author={Xu, Ying and Zhong, Xu and Yepes, Antonio Jose Jimeno and Lau, Jey Han},
  journal={arXiv preprint arXiv:2001.07820},
  year={2020}
}

%HotFlip
@article{ebrahimi2017hotflip,
  title={Hotflip: White-box adversarial examples for text classification},
  author={Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing},
  journal={arXiv preprint arXiv:1712.06751},
  year={2017}
}


%textbugger
@article{li2018textbugger,
  title={Textbugger: Generating adversarial text against real-world applications},
  author={Li, Jinfeng and Ji, Shouling and Du, Tianyu and Li, Bo and Wang, Ting},
  journal={arXiv preprint arXiv:1812.05271},
  year={2018}
}

@inproceedings{papernot2016crafting,
  title={Crafting adversarial input sequences for recurrent neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Swami, Ananthram and Harang, Richard},
  booktitle={MILCOM 2016-2016 IEEE Military Communications Conference},
  pages={49--54},
  year={2016},
  organization={IEEE}
}


@article{samanta2017towards,
  title={Towards crafting text adversarial samples},
  author={Samanta, Suranjana and Mehta, Sameep},
  journal={arXiv preprint arXiv:1707.02812},
  year={2017}
}

@article{pavlopoulos2014aspect,
  title={Aspect based sentiment analysis},
  author={Pavlopoulos, Ioannis},
  journal={Athens University of Economics and Business},
  year={2014}
}


@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={IEEE}
}

% BERT Embedding Layers 
@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}






% Method

%Leet
@article{perea2008r34d1ng,
  title={R34d1ng w0rd5 w1th numb3r5.},
  author={Perea, Manuel and Du{\~n}abeitia, Jon Andoni and Carreiras, Manuel},
  journal={Journal of Experimental Psychology: Human Perception and Performance},
  volume={34},
  number={1},
  pages={237},
  year={2008},
  publisher={American Psychological Association}
}
@book{thomas2002hacker,
  title={Hacker culture},
  author={Thomas, Douglas},
  year={2002},
  publisher={U of Minnesota Press}
}

@inproceedings{rizzo2016content,
  title={Content-preserving text watermarking through unicode homoglyph substitution},
  author={Rizzo, Stefano Giovanni and Bertini, Flavio and Montesi, Danilo},
  booktitle={Proceedings of the 20th International Database Engineering \& Applications Symposium},
  pages={97--104},
  year={2016}
}

% Spelling mistakes
@article{sun2020adv,
  title={Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT},
  author={Sun, Lichao and Hashimoto, Kazuma and Yin, Wenpeng and Asai, Akari and Li, Jia and Yu, Philip and Xiong, Caiming},
  journal={arXiv preprint arXiv:2003.04985},
  year={2020}
}
